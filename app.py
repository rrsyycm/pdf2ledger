import streamlit as st
import pandas as pd
import camelot
import plotly.express as px

from Category import CategoryManager

st.set_page_config(page_title="PDF äº¤æ˜“è®°å½•åˆ†æ", layout="wide")

# --------------- ğŸ§­ ä¾§è¾¹æ  ---------------
st.sidebar.title("ğŸ“‹ åˆ†ç±»ç®¡ç†")
# é»˜è®¤æ•°æ® + é…ç½®è·¯å¾„
DEFAULT_CATEGORY_MAP = {
    "é¤é¥®": ["è‚¯å¾·åŸº", "éº¦å½“åŠ³", "å¥¶èŒ¶", "é¢é¦†", "æ—©é¤"],
    "å•†è¶…é›¶å”®": ["è¶…å¸‚", "æ°´æœ", "é›¶é£Ÿ", "ä¾¿åˆ©åº—"],
    "é€šä¿¡": ["ä¸­å›½è”é€š", "ç§»åŠ¨", "ç”µä¿¡", "å®½å¸¦", "åˆ˜çŒ›"],
}
CONFIG_PATH = "category_config.yaml"

# åˆå§‹åŒ– manager
if "manager" not in st.session_state:
    st.session_state.manager = CategoryManager(CONFIG_PATH, DEFAULT_CATEGORY_MAP)

manager: CategoryManager = st.session_state.manager

# è¡¨æ ¼ç¼–è¾‘
df = manager.to_dataframe()

edited_df = st.sidebar.data_editor(
    df,
    use_container_width=True,
    num_rows="dynamic",
    column_config={
        "åˆ†ç±»": st.column_config.TextColumn(disabled=False),
        "å…³é”®è¯ï¼ˆé€—å·åˆ†éš”ï¼‰": st.column_config.TextColumn(),
    }
)

# ä¿å­˜
if st.sidebar.button("ğŸ’¾ ä¿å­˜é…ç½®"):
    try:
        manager.from_dataframe(edited_df)
        manager.save()
        st.success("âœ… é…ç½®ä¿å­˜æˆåŠŸï¼")
    except Exception as e:
        st.error(f"âŒ ä¿å­˜å¤±è´¥: {e}")


@st.cache_data
def extract_filtered_data(pdf_path):
    columns = [3.01, 4.32, 5.61, 7.12, 8.75, 11.12, 12.43, 13.73]
    scaled_columns = [str(int(round(x * 28.3))) for x in columns]
    columns_string = ",".join(scaled_columns)

    tables = camelot.read_pdf(
        pdf_path,
        flavor="stream",
        pages="all",
        row_tol=10,
        strip_text="\n",
        columns=[columns_string],
    )
    filtered_tables = []

    def classify_opponent(opponent):
        if not isinstance(opponent, str) or not opponent.strip():
            return "å…¶ä»–"

        opponent = opponent.strip()
        for category, keywords in manager.to_dict().items():
            for keyword in keywords:
                if keyword in opponent:
                    return category
        return "å…¶ä»–"

    KANGXI_MAP = {"â¼€": "ä¸€", "â¼„": "ä¹™", "â¼†": "äºŒ", "â¼ˆ": "äºº", "â¼‰": "å„¿", "â¼Š": "å…¥", "â¼‹": "å…«", "â¼": "å‡ ", "â¼‘": "åˆ€",
                  "â¼’": "åŠ›", "â¼”": "åŒ•", "â¼—": "å", "â¼˜": "åœ", "â¼š": "å‚", "â¼œ": "åˆ", "â¼": "å£", "â¼": "å£", "â¼Ÿ": "åœŸ",
                  "â¼ ": "å£«", "â¼£": "å¤•", "â¼¤": "å¤§", "â¼¥": "å¥³", "â¼¦": "å­", "â¼¨": "å¯¸", "â¼©": "å°", "â¼«": "å°¸", "â¼­": "å±±",
                  "â¼¯": "å·¥", "â¼°": "å·±", "â¼²": "å¹²", "â¼´": "å¹¿", "â¼¸": "å¼“", "â¼¼": "å¿ƒ", "â¼½": "æˆˆ", "â¼¿": "æ‰‹", "â½€": "æ”¯",
                  "â½‚": "æ–‡", "â½ƒ": "æ–—", "â½„": "æ–¤", "â½…": "æ–¹", "â½†": "æ— ", "â½‡": "æ—¥", "â½ˆ": "æ›°", "â½‰": "æœˆ", "â½Š": "æœ¨",
                  "â½‹": "æ¬ ", "â½Œ": "æ­¢", "â½": "æ­¹", "â½": "æ¯‹", "â½": "æ¯”", "â½‘": "æ¯›", "â½’": "æ°", "â½“": "æ°”", "â½”": "æ°´",
                  "â½•": "ç«", "â½–": "çˆª", "â½—": "çˆ¶", "â½š": "ç‰‡", "â½›": "ç‰™", "â½œ": "ç‰›", "â½": "çŠ¬", "â½": "ç„", "â½Ÿ": "ç‰",
                  "â½ ": "ç“œ", "â½¡": "ç“¦", "â½¢": "ç”˜", "â½£": "ç”Ÿ", "â½¤": "ç”¨", "â½¥": "ç”°", "â½©": "ç™½", "â½ª": "çš®", "â½«": "çš¿",
                  "â½¬": "ç›®", "â½­": "çŸ›", "â½®": "çŸ¢", "â½¯": "çŸ³", "â½°": "ç¤º", "â½²": "ç¦¾", "â½³": "ç©´", "â½´": "ç«‹", "â½µ": "ç«¹",
                  "â½¶": "ç±³", "â½¸": "ç¼¶", "â½¹": "ç½‘", "â½º": "ç¾Š", "â½»": "ç¾½", "â½¼": "è€", "â½½": "è€Œ", "â½¿": "è€³", "â¾": "è‚‰",
                  "â¾‚": "è‡£", "â¾ƒ": "è‡ª", "â¾„": "è‡³", "â¾†": "èˆŒ", "â¾ˆ": "èˆŸ", "â¾‰": "è‰®", "â¾Š": "è‰²", "â¾": "è™«", "â¾": "è¡€",
                  "â¾": "è¡Œ", "â¾": "è¡£", "â¾’": "å„¿", "â¾“": "è§’", "â¾”": "è¨€", "â¾•": "è°·", "â¾–": "è±†", "â¾š": "èµ¤", "â¾›": "èµ°",
                  "â¾œ": "è¶³", "â¾": "èº«", "â¾": "è½¦", "â¾Ÿ": "è¾›", "â¾ ": "è¾°", "â¾¢": "é‚‘", "â¾£": "é…‰", "â¾¤": "é‡‡", "â¾¥": "é‡Œ",
                  "â¾¦": "é‡‘", "â¾§": "é•¿", "â¾¨": "é—¨", "â¾©": "é˜œ", "â¾ª": "éš¶", "â¾¬": "é›¨", "â¾­": "é’", "â¾®": "é", "â¾¯": "é¢",
                  "â¾°": "é©", "â¾²": "éŸ­", "â¾³": "éŸ³", "â¾´": "é¡µ", "â¾µ": "é£", "â¾¶": "é£", "â¾·": "é£Ÿ", "â¾¸": "é¦–", "â¾¹": "é¦™",
                  "â¾º": "é©¬", "â¾»": "éª¨", "â¾¼": "é«˜", "â¿": "é¬¼", "â¿‚": "é±¼", "â¿ƒ": "é¸Ÿ", "â¿„": "å¤", "â¿…": "é¹¿", "â¿‡": "éº»",
                  "â¿‰": "é»", "â¿Š": "é»‘", "â¿": "é¼", "â¿": "é¼“", "â¿": "é¼ ", "â¿": "é¼»", "â¿’": "é½¿", "â¿“": "é¾™", "â¿”": "é¾Ÿ",
                  "â¿•": "ä»‘", "â»": "é£Ÿ", "â»¥": "é±¼"}

    # æ„é€  translate å­—å…¸
    TRANSLATION_TABLE = str.maketrans(KANGXI_MAP)

    def normalize_text(text):
        if not isinstance(text, str):
            return text
        return text.translate(TRANSLATION_TABLE)

    def update_cols(row):
        val7 = row[6]
        if isinstance(val7, str) and " " in val7:
            parts = val7.split(" ", 1)  # åªåˆ†å‰²ç¬¬ä¸€ä¸ªç©ºæ ¼
            row[5] = parts[0]
            row[6] = parts[1]
        return row

    for table in tables:
        df = table.df

        df = df.apply(update_cols, axis=1)
        filtered_df = df[df.iloc[:, 0].str.match(r"^\d{8}$", na=False)]
        filtered_tables.append(filtered_df)

    result_df = pd.concat(filtered_tables, ignore_index=True)
    result_df.columns = ["æ—¥æœŸ", "æ—¶é—´", "æ”¶æ”¯æ–¹å¼", "é‡‘é¢", "ä½™é¢", "å¯¹æ‰‹ä¿¡æ¯", "å¯¹æ‰‹è´¦å·", "äº¤æ˜“æ¸ é“", "äº¤æ˜“é™„è¨€"]
    result_df["é‡‘é¢"] = result_df["é‡‘é¢"].str.replace(",", "").astype(float)
    for col in ["å¯¹æ‰‹ä¿¡æ¯"]:
        result_df[col] = result_df[col].apply(normalize_text)
    for col in ["æ”¶æ”¯æ–¹å¼"]:
        result_df[col] = result_df[col].apply(normalize_text)
    result_df["æ¶ˆè´¹ç±»åˆ«"] = result_df["å¯¹æ‰‹ä¿¡æ¯"].apply(classify_opponent)
    result_df["æ—¥æœŸ"] = pd.to_datetime(result_df["æ—¥æœŸ"], format="%Y%m%d")

    return result_df


st.title("ğŸ“Š PDF äº¤æ˜“è®°å½•åˆ†æå·¥å…·")

# æ–‡ä»¶ä¸Šä¼ 
uploaded_file = st.file_uploader("ä¸Šä¼  PDF æ–‡ä»¶", type="pdf")

if uploaded_file:
    with st.spinner("æ­£åœ¨è§£æ PDF..."):
        df = extract_filtered_data(uploaded_file)

    st.success(f"æˆåŠŸæå– {len(df)} æ¡è®°å½•")

    # ç­›é€‰é¡¹
    st.sidebar.header("ğŸ” ç­›é€‰æ¡ä»¶")

    # æ—¥æœŸèŒƒå›´
    min_date = df["æ—¥æœŸ"].min()
    max_date = df["æ—¥æœŸ"].max()
    date_range = st.sidebar.date_input("æ—¥æœŸèŒƒå›´", (min_date, max_date))

    # æ”¶æ”¯æ–¹å¼
    iu_options = df["æ”¶æ”¯æ–¹å¼"].unique().tolist()
    # æ’é™¤ "æ­£å¸¸è¿˜æ¬¾"
    exclude_items = ["æ­£å¸¸è¿˜æ¬¾", "ç¨‹æ”¯ä»˜"]
    iu_default = [item for item in iu_options if item not in exclude_items]
    iu_channels = st.sidebar.multiselect("æ”¶æ”¯æ–¹å¼", iu_options, default=iu_default)

    # å¯¹æ‰‹
    opponent_options = df["å¯¹æ‰‹ä¿¡æ¯"].unique().tolist()
    opponent_channels = st.sidebar.multiselect("å¯¹æ‰‹ä¿¡æ¯", opponent_options, default=[])

    # æ¸ é“
    channel_options = df["äº¤æ˜“æ¸ é“"].unique().tolist()
    selected_channels = st.sidebar.multiselect("äº¤æ˜“æ¸ é“", channel_options, default=[])

    # ç±»åˆ«
    category_options = df["æ¶ˆè´¹ç±»åˆ«"].unique().tolist()
    selected_categories = st.sidebar.multiselect("æ¶ˆè´¹ç±»åˆ«", category_options, default=[])

    # åº”ç”¨ç­›é€‰
    filtered_df = df[
        (df["æ—¥æœŸ"] >= pd.to_datetime(date_range[0])) &
        (df["æ—¥æœŸ"] <= pd.to_datetime(
            date_range[1] if date_range and len(date_range) >= 2 and date_range[1] else pd.Timestamp.today()))

        ]

    if opponent_channels:
        filtered_df = filtered_df[filtered_df["å¯¹æ‰‹ä¿¡æ¯"].isin(opponent_channels)]

    if selected_channels:
        filtered_df = filtered_df[filtered_df["äº¤æ˜“æ¸ é“"].isin(selected_channels)]

    if selected_categories:
        filtered_df = filtered_df[filtered_df["æ¶ˆè´¹ç±»åˆ«"].isin(selected_categories)]

    if iu_channels:
        filtered_df = filtered_df[filtered_df["æ”¶æ”¯æ–¹å¼"].isin(iu_channels)]

    # æ˜¾ç¤ºç»“æœ
    st.subheader("ğŸ“Œ ç»Ÿè®¡ç»“æœ")
    st.metric("æ€»é‡‘é¢", f"{filtered_df['é‡‘é¢'].sum():,.2f}")
    st.metric("äº¤æ˜“ç¬”æ•°", f"{len(filtered_df)}")

    st.subheader("ğŸ“ˆ å„ç±»æ¶ˆè´¹æ±‡æ€»")

    # åˆ†ç»„ç»Ÿè®¡é‡‘é¢å’Œç¬”æ•°
    category_summary = (
        filtered_df.groupby("æ¶ˆè´¹ç±»åˆ«")
        .agg(æ€»é‡‘é¢=("é‡‘é¢", "sum"), ç¬”æ•°=("é‡‘é¢", "count"), å¹³å‡å•ç¬”=("é‡‘é¢", "mean"))
        .sort_values("æ€»é‡‘é¢", ascending=False)
        .reset_index()
    )

    # æ˜¾ç¤ºç»“æœè¡¨æ ¼
    st.dataframe(category_summary, use_container_width=True)

    st.subheader("ğŸ“ˆ å„ç±»æ¶ˆè´¹æ±‡æ€»é¥¼å›¾")
    # ä»…ä¿ç•™æ”¯å‡ºç±»æ•°æ®ï¼ˆæ€»é‡‘é¢ < 0ï¼‰
    expense_summary = category_summary[
        (category_summary["æ€»é‡‘é¢"] < 0)
    ].copy()
    expense_summary["æ”¯å‡ºé‡‘é¢"] = expense_summary["æ€»é‡‘é¢"].abs()  # è½¬ä¸ºæ­£æ•°ç”¨äºé¥¼å›¾æ˜¾ç¤º

    # é¥¼å›¾å±•ç¤º
    fig = px.pie(
        expense_summary,
        names="æ¶ˆè´¹ç±»åˆ«",
        values="æ”¯å‡ºé‡‘é¢",
        title="å„ç±»æ¶ˆè´¹å æ¯”ï¼ˆæŒ‰æ€»é‡‘é¢ï¼‰",
        hole=0.3  # å¯é€‰ï¼šè®©é¥¼å›¾ä¸­é—´æœ‰ç©ºæ´å˜æˆç¯å½¢å›¾
    )
    st.plotly_chart(fig, use_container_width=True)

    st.subheader("ğŸ“‹ äº¤æ˜“æ˜ç»†")
    columns_to_show = [col for col in filtered_df.columns if col != "ä½™é¢"]
    st.dataframe(filtered_df[columns_to_show], use_container_width=True)

    st.download_button("ä¸‹è½½ç»“æœ CSV", filtered_df.to_csv(index=False), "ç­›é€‰ç»“æœ.csv", "text/csv")

else:
    st.info("è¯·ä¸Šä¼ ä¸€ä»½ PDF æ–‡ä»¶ä»¥å¼€å§‹åˆ†æã€‚")
